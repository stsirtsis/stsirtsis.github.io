<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Stratis Tsirtsis </title> <meta name="author" content="Stratis Tsirtsis"> <meta name="description" content="My personal academic website. "> <meta name="keywords" content="machine-learning, artificial-intelligence, research, academic-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://stsirtsis.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Stratis</span> Tsirtsis </h1> <p class="desc">Final-year PhD candidate @ <a href="https://mpi-sws.org/" rel="external nofollow noopener" target="_blank">Max Planck Institute for Software Systems</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?2a740d8e853868742739ae9c92020bf4" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>Paul-Ehrlich-Stra√üe 26</p> <p>Kaiserslautern, Germany</p> </div> </div> <div class="clearfix"> <p>üëãüèº <strong>Hey there!</strong> I am Stratis, and I am currently pursuing a PhD in computer science, fortunate to be advised by <a href="https://people.mpi-sws.org/~manuelgr/" rel="external nofollow noopener" target="_blank">Manuel Gomez-Rodriguez</a>. I have spent fall 2023 as a research intern at <a href="https://ai.meta.com/" rel="external nofollow noopener" target="_blank">Meta AI (FAIR)</a> and spring 2023 as a visitor at <a href="https://www.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford University</a> working with <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/" rel="external nofollow noopener" target="_blank">Tobias Gerstenberg</a>. Before starting my PhD, I studied electrical &amp; computer engineering at the <a href="https://ntua.gr/en/" rel="external nofollow noopener" target="_blank">National Technical University of Athens</a>, where I completed my diploma thesis supervised by <a href="http://www.softlab.ntua.gr/~fotakis/" rel="external nofollow noopener" target="_blank">Dimitris Fotakis</a>.</p> <p>At a high-level, I am interested in building AI systems to understand, inform and complement human decisions and judgments in uncertain and high-stakes environments. During my PhD, I have focused mostly on developing <strong>machine learning</strong> methods for (i) decision making in the presence of strategic human behavior and (ii) counterfactual analysis of sequential decision making tasks. In a nutshell, my <strong>research interests</strong> lie in the intersection of machine learning and:</p> <ul> <li>causal inference</li> <li>game theory</li> <li>combinatorial &amp; convex optimization</li> <li>algorithmic fairness</li> <li>computational cognitive science</li> </ul> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#2698BA"> <div>Journal</div> </abbr> </div> <div id="tsirtsis2019optimal" class="col-sm-8"> <div class="title">Optimal Decision Making Under Strategic Behavior</div> <div class="author"> <em>Stratis Tsirtsis</em>,¬†Behzad Tabibian,¬†Moein Khajehnejad,¬†Adish Singla,¬†Bernhard Sch√∂lkopf,¬†and¬†Manuel Gomez-Rodriguez </div> <div class="periodical"> <em>Management Science</em>, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://pubsonline.informs.org/doi/full/10.1287/mnsc.2021.02567" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> <a class="bibnote btn btn-sm z-depth-0" role="button">Note</a> </div> <div class="abstract hidden"> <p>We are witnessing an increasing use of data-driven predictive models to inform decisions. As decisions have implications for individuals and society, there is increasing pressure on decision makers to be transparent about their decision policies. At the same time, individuals may use knowledge, gained by transparency, to invest effort strategically in order to maximize their chances of receiving a beneficial decision. Our goal is to find decision policies that are optimal in terms of utility in such a strategic setting. To this end, we first characterize how strategic investment of effort by individuals leads to a change in the feature distribution. Using this characterization, we first show that, in general, we cannot expect to find optimal decision policies in polynomial time and there are cases in which deterministic policies are suboptimal. Then, we demonstrate that, if the cost individuals pay to change their features satisfies a natural monotonicity assumption, we can narrow down the search for the optimal policy to a particular family of decision policies with a set of desirable properties, which allow for a highly effective polynomial time heuristic search algorithm using dynamic programming. Finally, under no assumptions on the cost individuals pay to change their features, we develop an iterative search algorithm that is guaranteed to find locally optimal decision policies also in polynomial time. Experiments on synthetic and real credit card data illustrate our theoretical findings and show that the decision policies found by our algorithms achieve higher utility than those that do not account for strategic behavior.</p> </div> <div class="bibnote hidden"> <p>A preliminary version appeared at the <em>NeurIPS Workshop on Human-Centric Machine Learning</em>, 2019.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00ab37"> <div>Conference</div> </abbr> </div> <div id="tsirtsis2023finding" class="col-sm-8"> <div class="title">Finding Counterfactually Optimal Action Sequences in Continuous State Spaces</div> <div class="author"> <em>Stratis Tsirtsis</em>,¬†and¬†Manuel Gomez-Rodriguez </div> <div class="periodical"> <em>37th Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/09ae6beae5f1ff38f05c05979097ea0f-Abstract-Conference.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> <a class="bibnote btn btn-sm z-depth-0" role="button">Note</a> </div> <div class="abstract hidden"> <p>Whenever a clinician reflects on the efficacy of a sequence of treatment decisions for a patient, they may try to identify critical time steps where, had they made different decisions, the patient‚Äôs health would have improved. While recent methods at the intersection of causal inference and reinforcement learning promise to aid human experts, as the clinician above, to retrospectively analyze sequential decision making processes, they have focused on environments with finitely many discrete states. However, in many practical applications, the state of the environment is inherently continuous in nature. In this paper, we aim to fill this gap. We start by formally characterizing a sequence of discrete actions and continuous states using finite horizon Markov decision processes and a broad class of bijective structural causal models. Building upon this characterization, we formalize the problem of finding counterfactually optimal action sequences and show that, in general, we cannot expect to solve it in polynomial time. Then, we develop a search method based on the A* algorithm that, under a natural form of Lipschitz continuity of the environment‚Äôs dynamics, is guaranteed to return the optimal solution to the problem. Experiments on real clinical data show that our method is very efficient in practice, and it has the potential to offer interesting insights for sequential decision making tasks.</p> </div> <div class="bibnote hidden"> <p>A preliminary version appeared at the <em>ICML Workshop on Counterfactuals in Minds and Machines</em>, 2023.</p> </div> </div> </div> </li> </ol> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 05, 2024</th> <td> Our paper <a href="https://osf.io/preprints/psyarxiv/m4yad" rel="external nofollow noopener" target="_blank">Towards a computational model of responsibility judgments in sequential human-AI collaboration</a> has been accepted at <a href="https://cognitivesciencesociety.org/cogsci-2024/" rel="external nofollow noopener" target="_blank">CogSci 2024</a>! üéâ </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 23, 2023</th> <td> I visited and gave a research talk at <a href="https://www.athenarc.gr/en/home" rel="external nofollow noopener" target="_blank">Athena Research Center</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 22, 2023</th> <td> Our paper <a href="https://arxiv.org/abs/2306.03929" rel="external nofollow noopener" target="_blank">Finding Counterfactually Optimal Action Sequences in Continuous State Spaces</a> has been accepted at <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS 2023</a>! üéâ </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 05, 2023</th> <td> Our paper <a href="https://arxiv.org/abs/1905.09239" rel="external nofollow noopener" target="_blank">Optimal Decision Making Under Strategic Behavior</a> has been accepted at <a href="https://pubsonline.informs.org/journal/mnsc" rel="external nofollow noopener" target="_blank">Management Science</a>! üéâ </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 30, 2023</th> <td> We organized a <a href="https://sites.google.com/view/counterfactuals-icml/home" rel="external nofollow noopener" target="_blank">workshop on counterfactuals in minds and machines at ICML 2023</a>. Recordings are available <a href="https://icml.cc/virtual/2023/workshop/21482" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 21, 2023</th> <td> I visited and gave research talks at <a href="https://www.harvard.edu/" rel="external nofollow noopener" target="_blank">Harvard University</a> and <a href="https://www.columbia.edu/" rel="external nofollow noopener" target="_blank">Columbia University</a>. </td> </tr> </table> </div> </div> <div class="triviabtn"> <a class="trivia btn btn-sm z-depth-0" role="button">Trivia</a> </div> <div class="trivia hidden"> <p>I grew up on a beautiful Greek island called <a href="https://www.youtube.com/watch?v=BY2RUJdH2Is" rel="external nofollow noopener" target="_blank">Lesvos</a>. Even though my name is rare in Greece, on the island there is a Stratis in every second house. The correct way to pronounce it is "Strah-tee-s", like in "stra(tegy)", "tee(th)", and "c(ereal)".</p> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%73%74%73%69%72%74%73%69%73[%61%74]%6D%70%69-%73%77%73[%64%6F%74]%6F%72%67" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=zUNYVu4AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/stsirtsis" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/stsirtsis" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/stratis_" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">If you want to get in touch, feel free to send me an email or ping me on twitter (now X). </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Stratis Tsirtsis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> and based on the <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?55c77e9337b17292fc29cc3db48d637e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>